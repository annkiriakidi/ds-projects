{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Секція 1. Логістична регресія з нуля.**\n",
        "\n",
        "Будемо крок за кроком будувати модель лог регресії з нуля для передбачення, чи буде врожай більше за 80 яблук (задача подібна до лекційної, але на класифікацію).\n",
        "\n",
        "Давайте нагадаємо основні формули для логістичної регресії.\n",
        "\n",
        "### Функція гіпотези - обчислення передбачення у логістичній регресії:\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\sigma(x W^T + b) = \\frac{1}{1 + e^{-(x W^T + b)}}\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ \\hat{y} $ — це ймовірність \"позитивного\" класу.\n",
        "- $ x $ — це вектор (або матриця для набору прикладів) вхідних даних.\n",
        "- $ W $ — це вектор (або матриця) вагових коефіцієнтів моделі.\n",
        "- $ b $ — це зміщення (bias).\n",
        "- $ \\sigma(z) $ — це сигмоїдна функція активації.\n",
        "\n",
        "### Як обчислюється сигмоїдна функція:\n",
        "\n",
        "Сигмоїдна функція $ \\sigma(z) $ має вигляд:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "Ця функція перетворює будь-яке дійсне значення $ z $ в інтервал від 0 до 1, що дозволяє інтерпретувати вихід як ймовірність для логістичної регресії.\n",
        "\n",
        "### Формула функції втрат для логістичної регресії (бінарна крос-ентропія):\n",
        "\n",
        "Функція втрат крос-ентропії оцінює, наскільки добре модель передбачає класи, порівнюючи передбачені ймовірності $ \\hat{y} $ із справжніми мітками $ y $. Формула наступна:\n",
        "\n",
        "$$\n",
        "L(y, \\hat{y}) = - \\left[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\right]\n",
        "$$\n",
        "\n",
        "Де:\n",
        "- $ y $ — це справжнє значення (мітка класу, 0 або 1).\n",
        "- $ \\hat{y} $ — це передбачене значення (ймовірність).\n",
        "\n"
      ],
      "metadata": {
        "id": "lbLHTNfSclli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\n",
        "Тут вже наведений код для ініціювання набору даних в форматі numpy. Перетворіть `inputs`, `targets` на `torch` тензори. Виведіть результат на екран."
      ],
      "metadata": {
        "id": "GtOYB-RHfc_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "3BNXSR-VdYKQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QLKZ77x4v_-v"
      },
      "outputs": [],
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "id": "KjoeaDrk6fO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0833b6a5-ad2f-4690-f4c2-16a0444f6ce4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Ініціюйте ваги `w`, `b` для моделі логістичної регресії потрібної форми зважаючи на розмірності даних випадковими значеннями з нормального розподілу. Лишаю тут код для фіксації `random_seed`."
      ],
      "metadata": {
        "id": "iKzbJKfOgGV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(1)"
      ],
      "metadata": {
        "id": "aXhKw6Tdj1-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee9ec24c-0ec7-4df6-ba4f-dab1c424a7bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7adf7a93cfb0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.randn(1, 3, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "eApcB7eb6h9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07d277b5-a740-4fd1-d2cb-d76f913acf99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6614, 0.2669, 0.0617]], requires_grad=True)\n",
            "tensor([0.6213], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Напишіть функцію `model`, яка буде обчислювати функцію гіпотези в логістичній регресії і дозволяти робити передбачення на основі введеного рядка даних і коефіцієнтів в змінних `w`, `b`.\n",
        "\n",
        "  **Важливий момент**, що функція `model` робить обчислення на `torch.tensors`, тож для математичних обчислень використовуємо фукнціонал `torch`, наприклад:\n",
        "  - обчсилення $e^x$: `torch.exp(x)`\n",
        "  - обчсилення $log(x)$: `torch.log(x)`\n",
        "  - обчислення середнього значення вектору `x`: `torch.mean(x)`\n",
        "\n",
        "  Використайте функцію `model` для обчислення передбачень з поточними значеннями `w`, `b`.Виведіть результат обчислень на екран.\n",
        "\n",
        "  Проаналізуйте передбачення. Чи не викликають вони у вас підозр? І якщо викликають, то чим це може бути зумовлено?"
      ],
      "metadata": {
        "id": "nYGxNGTaf5s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x):\n",
        "    z = x @ w.T + b\n",
        "    return 1 / (1 + torch.exp(-z))\n",
        "\n",
        "preds = model(inputs)\n",
        "print(preds)\n"
      ],
      "metadata": {
        "id": "pSz2j4Fh6jBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6eceee6-c2aa-4fb4-e5ea-feb2fe0b37d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Висновки**\n",
        "\n",
        "Всі передбачення -- тільки клас 1."
      ],
      "metadata": {
        "id": "bBRz86yCq5Zt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Напишіть функцію `binary_cross_entropy`, яка приймає на вхід передбачення моделі `predicted_probs` та справжні мітки в даних `true_labels` і обчислює значення втрат (loss)  за формулою бінарної крос-ентропії для кожного екземпляра та вертає середні втрати по всьому набору даних.\n",
        "  Використайте функцію `binary_cross_entropy` для обчислення втрат для поточних передбачень моделі."
      ],
      "metadata": {
        "id": "O2AGM0Mb2yHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy(predicted_probs, true_labels, epsilon=1e-7):\n",
        "    predicted_probs = torch.clamp(predicted_probs, epsilon, 1 - epsilon) # додала маленьке значення epsilon для уникнення логарифму від нуля, а то результат був nan\n",
        "    loss = - (true_labels * torch.log(predicted_probs) + (1 - true_labels) * torch.log(1 - predicted_probs))\n",
        "    return torch.mean(loss)\n",
        "\n",
        "loss = binary_cross_entropy(preds, targets)\n",
        "print(loss)\n"
      ],
      "metadata": {
        "id": "1bWlovvx6kZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732bd14f-210a-44a5-a628-05e4363f824e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6.3770, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Зробіть зворотнє поширення помилки і виведіть градієнти за параметрами `w`, `b`. Проаналізуйте їх значення. Як гадаєте, чому вони саме такі?"
      ],
      "metadata": {
        "id": "ZFKpQxdHi1__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "\n",
        "print(w.grad)\n",
        "print(b.grad)\n"
      ],
      "metadata": {
        "id": "YAbXUNSJ6mCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da136e8-6583-4989-ba5c-7add6f910a95"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.]])\n",
            "tensor([0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Що сталось?**\n",
        "\n",
        "В цій задачі, коли ми ініціювали значення випадковими значеннями з нормального розподілу, насправді ці значення не були дуже гарними стартовими значеннями і привели до того, що градієнти стали дуже малими або навіть рівними нулю (це призводить до того, що градієнти \"зникають\"), і відповідно при оновленні ваг у нас не буде нічого змінюватись. Це називається `gradient vanishing`. Це відбувається через **насичення сигмоїдної функції активації.**\n",
        "\n",
        "У нашій задачі ми використовуємо сигмоїдну функцію активації, яка має такий вигляд:\n",
        "\n",
        "   $$\n",
        "   \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "   $$\n",
        "\n",
        "\n",
        "Коли значення $z$ дуже велике або дуже мале, сигмоїдна функція починає \"насичуватись\". Це означає, що для великих позитивних $z$ сигмоїда наближається до 1, а для великих негативних — до 0. В цих діапазонах градієнти починають стрімко зменшуватись і наближаються до нуля (бо градієнт - це похідна, похідна на проміжку функції, де вона паралельна осі ОХ, дорівнює 0), що робить оновлення ваг неможливим.\n",
        "\n",
        "![](https://editor.analyticsvidhya.com/uploads/27889vaegp.png)\n",
        "\n",
        "У логістичній регресії $ z = x \\cdot w + b $. Якщо ваги $w, b$ - великі, значення $z$ також буде великим, і сигмоїда перейде в насичену область, де градієнти дуже малі.\n",
        "\n",
        "Саме це сталося в нашій задачі, де великі випадкові значення ваг викликали насичення сигмоїдної функції. Це в свою чергу призводить до того, що під час зворотного поширення помилки (backpropagation) модель оновлює ваги дуже повільно або зовсім не оновлює. Це називається проблемою **зникнення градієнтів** (gradient vanishing problem).\n",
        "\n",
        "**Що ж робити?**\n",
        "Ініціювати ваги маленькими значеннями навколо нуля. Наприклад ми можемо просто в існуючій ініціалізації ваги розділити на 1000. Можна також використати інший спосіб ініціалізації вагів - інформація про це [тут](https://www.geeksforgeeks.org/initialize-weights-in-pytorch/).\n",
        "\n",
        "Як це робити - показую нижче. **Виконайте код та знову обчисліть передбачення, лосс і виведіть градієнти.**\n",
        "\n",
        "А я пишу пояснення, чому просто не зробити\n",
        "\n",
        "```\n",
        "w = torch.randn(1, 3, requires_grad=True)/1000\n",
        "b = torch.randn(1, requires_grad=True)/1000\n",
        "```\n",
        "\n",
        "Нам потрібно, аби тензори вагів були листовими (leaf tensors).\n",
        "\n",
        "1. **Що таке листовий тензор**\n",
        "Листовий тензор — це тензор, який був створений користувачем безпосередньо і з якого починається обчислювальний граф. Якщо такий тензор має `requires_grad=True`, PyTorch буде відслідковувати всі операції, виконані над ним, щоб правильно обчислювати градієнти під час навчання.\n",
        "\n",
        "2. **Чому ми використовуємо `w.data` замість звичайних операцій**\n",
        "Якщо ми просто виконали б операції, такі як `(w - 0.5) / 100`, ми б отримали **новий тензор**, який вже не був би листовим тензором, оскільки ці операції створюють **новий** тензор, а не модифікують існуючий.\n",
        "\n",
        "  Проте, щоб залишити наші тензори ваги `w` та зміщення `b` листовими і продовжити можливість відстеження градієнтів під час тренування, ми використовуємо атрибут `.data`. Цей атрибут дозволяє **виконувати операції in-place (прямо на існуючому тензорі)** без зміни самого об'єкта тензора. Отже, тензор залишається листовим, і PyTorch може коректно обчислювати його градієнти.\n",
        "\n",
        "3. **Чому важливо залишити тензор листовим**\n",
        "Якщо тензор більше не є листовим (наприклад, через проведення операцій, що створюють нові тензори), ви не зможете отримати градієнти за допомогою `w.grad` чи `b.grad` після виклику `loss.backward()`. Це може призвести до втрати можливості оновлення параметрів під час тренування моделі. В нашому випадку ми хочемо, щоб тензори `w` та `b` накопичували градієнти, тому вони повинні залишатись листовими.\n",
        "\n",
        "**Висновок:**\n",
        "Ми використовуємо `.data`, щоб виконати операції зміни значень на ваги і зміщення **in-place**, залишаючи їх листовими тензорами, які можуть накопичувати градієнти під час навчання. Це дозволяє коректно працювати механізму зворотного поширення помилки (backpropagation) і оновлювати ваги моделі."
      ],
      "metadata": {
        "id": "nDN1t1RujQsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Виконайте код та знову обчисліть передбачення, лосс і знайдіть градієнти та виведіть всі ці тензори на екран."
      ],
      "metadata": {
        "id": "rOPSQyttpVjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(1)\n",
        "w = torch.randn(1, 3, requires_grad=True)  # Листовий тензор\n",
        "b = torch.randn(1, requires_grad=True)     # Листовий тензор\n",
        "\n",
        "# in-place операції\n",
        "w.data = w.data / 1000\n",
        "b.data = b.data / 1000"
      ],
      "metadata": {
        "id": "-EBOJ3tsnRaD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x):\n",
        "    z = x @ w.T + b\n",
        "    return 1 / (1 + torch.exp(-z))\n",
        "\n",
        "preds = model(inputs)\n",
        "print(preds)\n",
        "\n",
        "def binary_cross_entropy(predicted_probs, true_labels, epsilon=1e-7):\n",
        "    loss = - (true_labels * torch.log(predicted_probs) + (1 - true_labels) * torch.log(1 - predicted_probs))\n",
        "    return torch.mean(loss)\n",
        "\n",
        "loss = binary_cross_entropy(preds, targets)\n",
        "print(loss)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print(w.grad)\n",
        "print(b.grad)\n",
        "\n"
      ],
      "metadata": {
        "id": "-JwXiSpX6orh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe428f8-a4e8-4723-e48f-031849373561"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5174],\n",
            "        [0.5220],\n",
            "        [0.5244],\n",
            "        [0.5204],\n",
            "        [0.5190]], grad_fn=<MulBackward0>)\n",
            "tensor(0.6829, grad_fn=<MeanBackward0>)\n",
            "tensor([[ -5.4417, -18.9853, -10.0682]])\n",
            "tensor([-0.0794])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Напишіть алгоритм градієнтного спуску, який буде навчати модель з використанням написаних раніше функцій і виконуючи оновлення ваг. Алгоритм має включати наступні кроки:\n",
        "\n",
        "  1. Генерація прогнозів\n",
        "  2. Обчислення втрат\n",
        "  3. Обчислення градієнтів (gradients) loss-фукнції відносно ваг і зсувів\n",
        "  4. Налаштування ваг шляхом віднімання невеликої величини, пропорційної градієнту (`learning_rate` домножений на градієнт)\n",
        "  5. Скидання градієнтів на нуль\n",
        "\n",
        "Виконайте градієнтний спуск протягом 1000 епох, обчисліть фінальні передбачення і проаналізуйте, чи вони точні?"
      ],
      "metadata": {
        "id": "RCdi44IT334o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-5\n",
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    preds = model(inputs)\n",
        "    loss = binary_cross_entropy(preds, targets)\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "        b -= learning_rate * b.grad\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "\n",
        "final_preds = model(inputs)\n",
        "print(final_preds)\n"
      ],
      "metadata": {
        "id": "mObHPyE06qsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852ce804-c4d5-4a57-cf18-199fca3e9fc2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5777],\n",
            "        [0.6685],\n",
            "        [0.9113],\n",
            "        [0.1616],\n",
            "        [0.8653]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Секція 2. Створення лог регресії з використанням функціоналу `torch.nn`.**\n",
        "\n",
        "Давайте повторно реалізуємо ту ж модель, використовуючи деякі вбудовані функції та класи з PyTorch.\n",
        "\n",
        "Даних у нас буде побільше - тож, визначаємо нові масиви."
      ],
      "metadata": {
        "id": "fuRhlyF9qAia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Вхідні дані (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70],\n",
        "                   [73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# Таргети (apples > 80)\n",
        "targets = np.array([[0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1],\n",
        "                    [1],\n",
        "                    [0],\n",
        "                    [1]], dtype='float32')"
      ],
      "metadata": {
        "id": "IX8Bhm74rV4M"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Завантажте вхідні дані та мітки в PyTorch тензори та з них створіть датасет, який поєднує вхідні дані з мітками, використовуючи клас `TensorDataset`. Виведіть перші 3 елементи в датасеті.\n",
        "\n"
      ],
      "metadata": {
        "id": "7X2dV30KtAPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "\n",
        "dataset = TensorDataset(inputs, targets)\n",
        "\n",
        "for i in range(3):\n",
        "    print(dataset[i])"
      ],
      "metadata": {
        "id": "chrvMfBs6vjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f646607f-8523-4899-ec13-c1786ecef559"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([73., 67., 43.]), tensor([0.]))\n",
            "(tensor([91., 88., 64.]), tensor([1.]))\n",
            "(tensor([ 87., 134.,  58.]), tensor([1.]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Визначте data loader з класом **DataLoader** для підготовленого датасету `train_ds`, встановіть розмір батчу на 5 та увімкніть перемішування даних для ефективного навчання моделі. Виведіть перший елемент в дата лоадері."
      ],
      "metadata": {
        "id": "4nMFaa8suOd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dl = DataLoader(dataset, batch_size=5, shuffle=True)\n",
        "\n",
        "for batch in train_dl:\n",
        "    print(batch)"
      ],
      "metadata": {
        "id": "ZCsRo5Mx6wEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d92fe5f-4c22-4dc9-ddcc-f098cde1518b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 69.,  96.,  70.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 73.,  67.,  43.],\n",
            "        [ 73.,  67.,  43.]]), tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]])]\n",
            "[tensor([[ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 73.,  67.,  43.]]), tensor([[1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])]\n",
            "[tensor([[ 91.,  88.,  64.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [ 69.,  96.,  70.]]), tensor([[1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Створіть клас `LogReg` для логістичної регресії, наслідуючи модуль `torch.nn.Module` за прикладом в лекції (в частині про FeedForward мережі).\n",
        "\n",
        "  У нас модель складається з лінійної комбінації вхідних значень і застосування фукнції сигмоїда. Тож, нейромережа буде складатись з лінійного шару `nn.Linear` і використання активації `nn.Sigmid`. У створеному класі мають бути реалізовані методи `__init__` з ініціалізацією шарів і метод `forward` для виконання прямого проходу моделі через лінійний шар і функцію активації.\n",
        "\n",
        "  Створіть екземпляр класу `LogReg` в змінній `model`."
      ],
      "metadata": {
        "id": "ymcQOo_hum6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LogReg(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3, 1)\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.activation(self.linear(x))\n",
        "\n",
        "model = LogReg()\n"
      ],
      "metadata": {
        "id": "EyAwhTBW6xxz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Задайте оптимізатор `Stockastic Gradient Descent` в змінній `opt` для навчання моделі логістичної регресії. А також визначіть в змінній `loss` функцію втрат `binary_cross_entropy` з модуля `torch.nn.functional` для обчислення втрат моделі. Обчисліть втрати для поточних передбачень і міток, а потім виведіть їх. Зробіть висновок, чи моделі вдалось навчитись?"
      ],
      "metadata": {
        "id": "RflV7xeVyoJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD\n",
        "\n",
        "opt = SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "for xb, yb in train_dl:\n",
        "    preds = model(xb)\n",
        "    loss = F.binary_cross_entropy(preds, yb)\n",
        "    print(loss)\n"
      ],
      "metadata": {
        "id": "3QCATPU_6yfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e83cb84-31c3-4789-a9d1-40d4d6baef0b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0002, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(3.5975, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(1.7987, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Візьміть з лекції функцію для тренування моделі з відстеженням значень втрат і навчіть щойно визначену модель на 1000 епохах. Виведіть після цього графік зміни loss, фінальні передбачення і значення таргетів."
      ],
      "metadata": {
        "id": "ch-WrYnKzMzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(1000):\n",
        "    for xb, yb in train_dl:\n",
        "        preds = model(xb)\n",
        "        loss = F.binary_cross_entropy(preds, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    losses.append(loss.item())\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "final_preds = model(inputs)\n",
        "print(final_preds)\n",
        "print(targets)\n"
      ],
      "metadata": {
        "id": "cEHQH9qE626k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "outputId": "7deb48ab-31d8-461b-f047-ac58ba099ec7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.7733e-01],\n",
            "        [8.6520e-01],\n",
            "        [1.0000e+00],\n",
            "        [1.1193e-12],\n",
            "        [1.0000e+00],\n",
            "        [1.7733e-01],\n",
            "        [8.6520e-01],\n",
            "        [1.0000e+00],\n",
            "        [1.1193e-12],\n",
            "        [1.0000e+00],\n",
            "        [1.7733e-01],\n",
            "        [8.6520e-01],\n",
            "        [1.0000e+00],\n",
            "        [1.1193e-12],\n",
            "        [1.0000e+00]], grad_fn=<SigmoidBackward0>)\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    }
  ]
}