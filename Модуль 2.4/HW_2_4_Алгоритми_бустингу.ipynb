{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "–í —Ü—å–æ–º—É –¥–æ–º–∞—à–Ω—å–æ–º—É –∑–∞–≤–¥–∞–Ω–Ω—ñ –º–∏ –∑–Ω–æ–≤—É –ø—Ä–∞—Ü—é—î–º–æ –∑ –¥–∞–Ω–∏–º–∏ –∑ –Ω–∞—à–æ–≥–æ –∑–º–∞–≥–∞–Ω–Ω—è [\"Bank Customer Churn Prediction (DLU Course)\"](https://www.kaggle.com/t/7c080c5d8ec64364a93cf4e8f880b6a0).\n",
        "\n",
        "–¢—É—Ç –º–∏ –ø–æ–±—É–¥—É—î–º–æ —Ä—ñ—à–µ–Ω–Ω—è –∑–∞–¥–∞—á—ñ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ –±—É—Å—Ç–∏–Ω–≥—É: XGBoost —Ç–∞ LightGBM, –∞ —Ç–∞–∫–æ–∂ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ –±—ñ–±–ª—ñ–æ—Ç–µ–∫—É HyperOpt –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤."
      ],
      "metadata": {
        "id": "fDefDHQt8LXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. –ó—á–∏—Ç–∞–π—Ç–µ –¥–∞–Ω—ñ `train.csv` –≤ –∑–º—ñ–Ω–Ω—É `raw_df` —Ç–∞ —Å–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ—Å—å –Ω–∞–≤–µ–¥–µ–Ω–∏–º –∫–æ–¥–æ–º –Ω–∏–∂—á–µ –∞–±–∏ —Ä–æ–∑–¥—ñ–ª–∏—Ç–∏ –¥–∞–Ω—ñ –Ω–∞ —Ç—Ä–Ω—É–≤–∞–ª—å–Ω—ñ —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω—ñ —ñ —Ä–æ–∑–¥—ñ–ª–∏—Ç–∏ –¥–∞–Ω—ñ –Ω–∞ –æ–∑–Ω–∞–∫–∏ –∑ –º–∞—Ç–∏—Ä–∏—Ü—ñ –• —Ç–∞ —Ü—ñ–ª—å–æ–≤—É –∑–º—ñ–Ω–Ω—É. –ù–∞–∑–≤–∏ –∑–º—ñ–Ω–Ω–∏—Ö `train_inputs, train_targets, train_inputs, train_targets` –º–æ–∂–Ω–∞ –∑–º—ñ–Ω–∏—Ç–∏ –Ω–∞ —Ç—ñ, —è–∫—ñ –í–∞–º –∑—Ä—É—á–Ω–æ.\n",
        "\n",
        "  –ù–∞–≤–µ–¥–µ–Ω–∏–π —Å–∫—Ä–∏–ø—Ç - —á–∞—Å—Ç–∏–Ω–∞ –æ—Ç—Ä–∏–º–∞–Ω–æ–≥–æ –º–Ω–æ—é —Å–∫—Ä–∏–ø—Ç–∞ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ –¥–∞–Ω–∏—Ö. –ú–∏ —Ç—É—Ç –Ω–µ –≤–∏–∫–Ω—É—î–º–æ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è —Ç–∞ –æ–±—Ä–æ–±–∫—É –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö, –±–æ —Ö–æ—á–µ–º–æ —Ü–µ –¥–µ–ª–µ–≥—É–≤–∞—Ç–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º, —è–∫—ñ –±—É–¥–µ–º–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏. –Ø–∫—â–æ —â–æ—Å—å –Ω–µ —Ä–æ–∑—É–º—ñ—î—Ç–µ –≤ –Ω–∞–≤–µ–¥–µ–Ω–∏—Ö —Å–∫—Ä–∏–ø—Ç–∞—Ö, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é —Ä–æ–∑—ñ–±—Ä–∞—Ç–∏—Å—å: –Ω–∞–≤–∏—á–∫–∞ —á–∏—Ç–∞—Ç–∏ –∫–æ–¥ - –≤–∞–∂–ª–∏–≤–∞ —Å–∫–ª–∞–¥–æ–≤–∞ —Ä–æ–±–æ—Ç–∏ –≤ –º–∞—à–∏–Ω–Ω–æ–º—É –Ω–∞–≤—á–∞–Ω–Ω—ñ."
      ],
      "metadata": {
        "id": "LhivzW9W8-Dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from hyperopt import hp, fmin, tpe, Trials\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "o3cNXkXhIsBs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Tuple, Dict, Any\n",
        "\n",
        "\n",
        "def split_train_val(df: pd.DataFrame, target_col: str, test_size: float = 0.2, random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Split the dataframe into training and validation sets.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The raw dataframe.\n",
        "        target_col (str): The target column for stratification.\n",
        "        test_size (float): The proportion of the dataset to include in the validation split.\n",
        "        random_state (int): Random state for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, pd.DataFrame]: Training and validation dataframes.\n",
        "    \"\"\"\n",
        "    train_df, val_df = train_test_split(df, test_size=test_size, random_state=random_state, stratify=df[target_col])\n",
        "    return train_df, val_df\n",
        "\n",
        "\n",
        "def separate_inputs_targets(df: pd.DataFrame, input_cols: list, target_col: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "    \"\"\"\n",
        "    Separate inputs and targets from the dataframe.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The dataframe.\n",
        "        input_cols (list): List of input columns.\n",
        "        target_col (str): Target column.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, pd.Series]: DataFrame of inputs and Series of targets.\n",
        "    \"\"\"\n",
        "    inputs = df[input_cols].copy()\n",
        "    targets = df[target_col].copy()\n",
        "    return inputs, targets"
      ],
      "metadata": {
        "id": "cKE8RTPf6CRD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df = pd.read_csv(\"train.csv\")\n",
        "\n",
        "raw_df = raw_df.drop(columns=[\"CustomerId\", \"Surname\"])\n",
        "\n",
        "categorical_cols = [\"Geography\", \"Gender\"]\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    raw_df[col] = le.fit_transform(raw_df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "def split_train_val(df, target_col, test_size=0.2, random_state=42):\n",
        "    return train_test_split(df, test_size=test_size, random_state=random_state, stratify=df[target_col])\n",
        "\n",
        "target_col = \"Exited\"\n",
        "train_df, val_df = split_train_val(raw_df, target_col)\n",
        "\n",
        "input_cols = [col for col in raw_df.columns if col != target_col]\n",
        "train_inputs, train_targets = train_df[input_cols], train_df[target_col]\n",
        "val_inputs, val_targets = val_df[input_cols], val_df[target_col]\n",
        "\n",
        "xgb_clf = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "xgb_clf.fit(train_inputs, train_targets)\n",
        "xgb_preds = xgb_clf.predict(val_inputs)\n",
        "xgb_acc = accuracy_score(val_targets, xgb_preds)\n",
        "\n",
        "lgb_clf = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "lgb_clf.fit(train_inputs, train_targets)\n",
        "lgb_preds = lgb_clf.predict(val_inputs)\n",
        "lgb_acc = accuracy_score(val_targets, lgb_preds)\n",
        "\n",
        "def objective_xgb(params):\n",
        "    clf = xgb.XGBClassifier(**params, random_state=42)\n",
        "    clf.fit(train_inputs, train_targets)\n",
        "    preds = clf.predict(val_inputs)\n",
        "    return -accuracy_score(val_targets, preds)\n",
        "\n",
        "space_xgb = {\n",
        "    'n_estimators': hp.choice('n_estimators', [50, 100, 200]),\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "    'max_depth': hp.choice('max_depth', [3, 5, 7]),\n",
        "}\n",
        "\n",
        "trials = Trials()\n",
        "best_xgb = fmin(fn=objective_xgb, space=space_xgb, algo=tpe.suggest, max_evals=20, trials=trials)\n",
        "\n",
        "print(\"XGBoost Accuracy:\", xgb_acc)\n",
        "print(\"LightGBM Accuracy:\", lgb_acc)\n",
        "print(\"Best XGBoost params:\", best_xgb)\n"
      ],
      "metadata": {
        "id": "-bHdMJVB4xQR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b37cc4-9d4b-4ac4-86a1-e6bcebdf1adc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001621 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1096\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:09<00:00,  2.04trial/s, best loss: -0.9]\n",
            "XGBoost Accuracy: 0.8946666666666667\n",
            "LightGBM Accuracy: 0.8963333333333333\n",
            "Best XGBoost params: {'learning_rate': 0.19145472794096244, 'max_depth': 0, 'n_estimators': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. –í —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–æ–º—É —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–æ–º—É –Ω–∞–±–æ—Ä—ñ –ø–µ—Ä–µ—Ç–≤–æ—Ä—ñ—Ç—å –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω—ñ –æ–∑–Ω–∞–∫–∏ –Ω–∞ —Ç–∏–ø `category`. –ú–æ–∂–Ω–∞ —Ü–µ –∑—Ä–æ–±–∏—Ç–∏ –¥–≤–æ–º–∞ —Å–ø–æ—Å–æ–±–∞–º–∏:\n",
        " 1. `df[col_name].astype('category')`, —è–∫ –±—É–ª–æ –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–æ–≤–∞–Ω–æ –≤ –ª–µ–∫—Ü—ñ—ó\n",
        " 2. –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ –º–µ—Ç–æ–¥ `pd.Categorical(df[col_name])`"
      ],
      "metadata": {
        "id": "cq0JU7MqHgp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = [\"Geography\", \"Gender\"]\n",
        "\n",
        "for col in categorical_cols:\n",
        "    train_df[col] = pd.Categorical(train_df[col])\n",
        "    val_df[col] = pd.Categorical(val_df[col])"
      ],
      "metadata": {
        "id": "UPmqo-Mr4yUO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. –ù–∞–≤—á—ñ—Ç—å –Ω–∞ –æ—Ç—Ä–∏–º–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö –º–æ–¥–µ–ª—å `XGBoostClassifier`. –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –∞–ª–≥–æ—Ä–∏—Ç–º—É –≤—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å –Ω–∞ —Å–≤—ñ–π —Ä–æ–∑—Å—É–¥, –º–∏ –¥–∞–ª—ñ –±—É–¥–µ–º–æ —ó—Ö —Ç—é–Ω–∏—Ç–∏. –†–µ–∫–æ–º–µ–Ω–¥—É—é —Ç—Ä–µ–Ω—É–≤–∞—Ç–∏ –Ω–µ –¥—É–∂–µ —Å–∫–ª–∞–¥–Ω—É –º–æ–¥–µ–ª—å.\n",
        "\n",
        "  –û–ø–∏—Å –≤—Å—ñ—Ö –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ XGBoostClassifier - —Ç—É—Ç https://xgboost.readthedocs.io/en/stable/parameter.html#global-config\n",
        "\n",
        "  **–í–∞–∂–ª–∏–≤–æ:** –∑—Ä–æ–±—ñ—Ç—å —Ç–∞–∫—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è `XGBoostClassifier` –∞–±–∏ –≤—ñ–Ω —Å–∞–º–æ—Å—Ç—ñ–π–Ω–æ –æ–±—Ä–æ–±–ª—è–≤ –Ω–µ–∑–∞–ø–æ–≤–Ω–µ–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –¥–∞–Ω–∏—Ö —ñ –æ–±—Ä–æ–±–ª—è–≤ –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏.\n",
        "\n",
        "  –ú–æ–∂–Ω–∞ —Ç–∞–∫–æ–∂, —è–∫—â–æ –ø—Ä–∞—Ü—é—î—Ç–µ –≤ Google Colab, —É–≤—ñ–º–∫–Ω—É—Ç–∏ –º–æ–∂–ª–∏–≤—ñ—Å—Ç—å –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è GPU (`Runtime -> Change runtime type -> T4 GPU`) —ñ –≤—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä `device='cuda'` –≤ `XGBoostClassifier` –¥–ª—è –ø—Ä–∏—à–≤–∏–¥—à–µ–Ω–Ω—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –±—É—Å—Ç–∏–Ω–≥ –º–æ–¥–µ–ª—ñ.\n",
        "  \n",
        "  –ü—ñ—Å–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ\n",
        "  1. –í–∏–º—ñ—Ä—è–π—Ç–µ —Ç–æ—á–Ω—ñ—Å—Ç—å –∑ –¥–æ–ø–æ–º–æ–≥–æ—é AUROC –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–æ–º—É —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–æ–º—É –Ω–∞–±–æ—Ä–∞—Ö.\n",
        "  2. –ó—Ä–æ–±—ñ—Ç—å –≤–∏—Å–Ω–æ–≤–æ–∫ –ø—Ä–æ –æ—Ç—Ä–∏–º–∞–Ω—É –º–æ–¥–µ–ª—å: –≤–æ–Ω–∞ —Ö–æ—Ä–æ—à–∞/–ø–æ–≥–∞–Ω–∞, —á–∏ —î high bias/high variance?\n",
        "  3. –ü–æ—Ä—ñ–≤–Ω—è–π—Ç–µ —è–∫—ñ—Å—Ç—å —Ü—ñ—î—ó –º–æ–¥–µ–ª—ñ –∑ —Ç–æ—é, —â–æ –≤–∏ –æ—Ç—Ä–º–∞–ª–∏ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º DecisionTrees —Ä–∞–Ω—ñ—à–µ. –ß–∏ –≤–∏–π—à–ª–æ –ø–æ–∫—Ä–∞—â–∏—Ç–∏ —è–∫—ñ—Å—Ç—å?"
      ],
      "metadata": {
        "id": "_LxWkv4o-wMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_clf = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    use_label_encoder=False,\n",
        "    tree_method='hist',\n",
        "    enable_categorical=True,\n",
        "    missing=np.nan,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_clf.fit(train_inputs, train_targets)\n",
        "\n",
        "train_preds_proba = xgb_clf.predict_proba(train_inputs)[:, 1]\n",
        "val_preds_proba = xgb_clf.predict_proba(val_inputs)[:, 1]\n",
        "\n",
        "train_auc = roc_auc_score(train_targets, train_preds_proba)\n",
        "val_auc = roc_auc_score(val_targets, val_preds_proba)\n",
        "\n",
        "print(\"Train AUROC:\", train_auc)\n",
        "print(\"Validation AUROC:\", val_auc)"
      ],
      "metadata": {
        "id": "_5rDqdDP41hb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d879e454-9646-427c-8db9-d5820c0c0c1c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train AUROC: 0.9730805964327622\n",
            "Validation AUROC: 0.9316510048700184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–í–∏—Å–Ω–æ–≤–∫–∏**\n",
        "\n",
        "–ë–∞–ª–∞–Ω—Å –º—ñ–∂ bias —ñ variance –≤–∏–≥–ª—è–¥–∞—î –¥–æ–±—Ä–µ."
      ],
      "metadata": {
        "id": "0BLwxKbgryve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ –±—ñ–±–ª—ñ–æ—Ç–µ–∫—É `Hyperopt` —ñ –ø—Ä–∏–∫–ª–∞–¥ –ø–æ—à—É–∫—É –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –¥–ª—è `XGBoostClassifier` –∑ –ª–µ–∫—Ü—ñ—ó –∑–Ω–∞–π–¥—ñ—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ `XGBoostClassifier` –¥–ª—è –Ω–∞—à–æ—ó –∑–∞–¥–∞—á—ñ. –ó–∞–¥–∞–π—Ç–µ —Å–≤–æ—é —Å—ñ—Ç–∫—É –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –≤–∏—Ö–æ–¥—è—á–∏ –∑ —Ç–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤, —è–∫—ñ –≤–∏ –± —Ö–æ—Ç—ñ–ª–∏ –ø–µ—Ä–µ–±—Ä–∞—Ç–∏. –ü–æ—Å—Ç–∞–≤—Ç–µ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–∞—É–Ω–¥—ñ–≤ –≤ –ø—ñ–¥–±–æ—Ä—ñ –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ —Ä—ñ–≤–Ω—É **20**.\n",
        "\n",
        "  **–£–≤–∞–≥–∞!** –î–ª—è —Ç–æ–≥–æ, –∞–±–∏ —Å–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏—Å—å hyperopt, –Ω–∞–º —Ç—Ä–µ–±–∞ –∑–∞–¥–∞—Ç–∏ —Ñ—É–Ω–∫—Ü—ñ—é `objective`. –í –Ω—ñ–π –º–∏ –º–∞—î–º–æ –∑–∞–¥–∞—Ç–∏ loss - —Ü–µ –º–æ–∂–µ –±—É–¥—å-—è–∫–∞ –º–µ—Ç—Ä–∏–∫–∞, –∞–ª–µ –±–∞–∂–∞–Ω–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤—Ç–∞–∏ —Ç—É, —è–∫–∞ —Ü—ñ–ª—å–æ–≤–∞ –≤ –≤–∞—à—ñ–π –∑–∞–¥–∞—á—ñ. –ß–∏–º –º–µ–Ω—à–∏–π –ª–æ—Å—Å - —Ç–∏–º –ª—ñ–ø—à–∞ –º–æ–¥–µ–ª—å –Ω–∞ –¥—É–º–∫—É hyperopt. –¢–æ–∂, —Ç—É—Ç –Ω–∞–º —Ç—Ä–µ–±–∞ –∑–∞–¥–∞—Ç–∏ loss - –Ω–µ–≥–∞—Ç–∏–≤–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è AUROC. –í –ª–µ–∫—Ü—ñ—ó –º–∏ –Ω–∞—Ç–æ–º—ñ—Å—Ç—å –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–ª–∏ Accuracy.\n",
        "\n",
        "  –ü—ñ—Å–ª—è —É—Å–ø—ñ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –ø–æ—à—É–∫—É –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏—Ö –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤\n",
        "    - –≤–∏–≤–µ–¥—ñ—Ç—å –Ω–∞–π–∫—Ä–∞—â—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤\n",
        "    - —Å—Ç–≤–æ—Ä—ñ—Ç—å –≤ –æ–∫—Ä–µ–º—ñ–π –∑–º—ñ–Ω—ñ–π `final_clf` –º–æ–¥–µ–ª—å `XGBoostClassifier` –∑ –Ω–∞–π–∫—Ä–∞—â–∏–º–∏ –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
        "    - –Ω–∞–≤—á—ñ—Ç—å –º–æ–¥–µ–ª—å `final_clf`\n",
        "    - –æ—Ü—ñ–Ω—ñ—Ç—å —è–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ `final_clf` –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ–π —ñ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω—ñ–π –≤–∏–±—ñ—Ä–∫–∞—Ö –∑ –¥–æ–ø–æ–º–æ–≥–æ—é AUROC.\n",
        "    - –∑—Ä–æ–±—ñ—Ç—å –≤–∏—Å–Ω–æ–≤–æ–∫ –ø—Ä–æ —è–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ. –ß–∏ —Å—Ç–∞–ª–∞ –≤–æ–Ω–∞ –∫—Ä–∞—â–µ –ø–æ—Ä—ñ–≤–Ω—è–Ω–æ –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–º –ø—É–Ω–∫—Ç–æ–º (2) —Ü—å–æ–≥–æ –∑–∞–≤–¥–∞–Ω–Ω—è?"
      ],
      "metadata": {
        "id": "U4hm5qYs_f7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "space_xgb = {\n",
        "    'n_estimators': hp.choice('n_estimators', [50, 100, 200]),\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "    'max_depth': hp.choice('max_depth', [3, 5, 7]),\n",
        "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0)\n",
        "}\n",
        "\n",
        "def objective_xgb(params):\n",
        "    clf = xgb.XGBClassifier(\n",
        "        **params,\n",
        "        use_label_encoder=False,\n",
        "        tree_method='hist',\n",
        "        enable_categorical=True,\n",
        "        missing=np.nan,\n",
        "        random_state=42\n",
        "    )\n",
        "    clf.fit(train_inputs, train_targets)\n",
        "    preds_proba = clf.predict_proba(val_inputs)[:, 1]\n",
        "    return -roc_auc_score(val_targets, preds_proba)\n",
        "\n",
        "trials = Trials()\n",
        "best_xgb = fmin(fn=objective_xgb, space=space_xgb, algo=tpe.suggest, max_evals=20, trials=trials)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_xgb)\n",
        "\n",
        "final_clf = xgb.XGBClassifier(\n",
        "    n_estimators=[50, 100, 200][best_xgb['n_estimators']],\n",
        "    learning_rate=best_xgb['learning_rate'],\n",
        "    max_depth=[3, 5, 7][best_xgb['max_depth']],\n",
        "    subsample=best_xgb['subsample'],\n",
        "    colsample_bytree=best_xgb['colsample_bytree'],\n",
        "    use_label_encoder=False,\n",
        "    tree_method='hist',\n",
        "    enable_categorical=True,\n",
        "    missing=np.nan,\n",
        "    random_state=42\n",
        ")\n",
        "final_clf.fit(train_inputs, train_targets)\n",
        "\n",
        "train_preds_proba = final_clf.predict_proba(train_inputs)[:, 1]\n",
        "val_preds_proba = final_clf.predict_proba(val_inputs)[:, 1]\n",
        "train_auc = roc_auc_score(train_targets, train_preds_proba)\n",
        "val_auc = roc_auc_score(val_targets, val_preds_proba)\n",
        "\n",
        "print(\"Train AUROC:\", train_auc)\n",
        "print(\"Validation AUROC:\", val_auc)"
      ],
      "metadata": {
        "id": "WhR1g9B4433r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "781a9426-66a0-465a-e118-336c35f3d697"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  5%|‚ñå         | 1/20 [00:00<00:03,  5.07trial/s, best loss: -0.9353467316002468]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10%|‚ñà         | 2/20 [00:00<00:04,  4.48trial/s, best loss: -0.9353467316002468]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 20%|‚ñà‚ñà        | 4/20 [00:00<00:03,  4.67trial/s, best loss: -0.9353467316002468]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 30%|‚ñà‚ñà‚ñà       | 6/20 [00:01<00:02,  4.69trial/s, best loss: -0.9353467316002468]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 40%|‚ñà‚ñà‚ñà‚ñà      | 8/20 [00:01<00:02,  5.32trial/s, best loss: -0.9353467316002468]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 10/20 [00:01<00:01,  5.86trial/s, best loss: -0.9353467316002468]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 12/20 [00:02<00:01,  6.42trial/s, best loss: -0.93589546608135]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 14/20 [00:02<00:00,  6.39trial/s, best loss: -0.9361417106797447]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 16/20 [00:02<00:00,  7.26trial/s, best loss: -0.9361417106797447]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 17/20 [00:02<00:00,  6.74trial/s, best loss: -0.9361417106797447]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 19/20 [00:03<00:00,  5.35trial/s, best loss: -0.936620481514507] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:03<00:00,  5.52trial/s, best loss: -0.936620481514507]\n",
            "Best Hyperparameters: {'colsample_bytree': 0.5116545453548452, 'learning_rate': 0.05507032544050008, 'max_depth': 0, 'n_estimators': 2, 'subsample': 0.6727346304084919}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [10:35:30] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train AUROC: 0.9433537715081971\n",
            "Validation AUROC: 0.936620481514507\n",
            "–ë–∞–ª–∞–Ω—Å –º—ñ–∂ bias —ñ variance –≤–∏–≥–ª—è–¥–∞—î –¥–æ–±—Ä–µ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–í–∏—Å–Ω–æ–≤–∫–∏.**\n",
        "\n",
        "–ë–∞–ª–∞–Ω—Å –º—ñ–∂ bias —ñ variance –≤–∏–≥–ª—è–¥–∞—î –¥–æ–±—Ä–µ. –ê–ª–µ —Å–∞–º—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏ —Ç—Ä–æ—Ö–∏ –≤–ø–∞–ª–∏ üò¢"
      ],
      "metadata": {
        "id": "6AQA9kcisivA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. –ù–∞–≤—á—ñ—Ç—å –Ω–∞ –Ω–∞—à–∏—Ö –¥–∞–Ω–∏—Ö –º–æ–¥–µ–ª—å LightGBM. –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –∞–ª–≥–æ—Ä–∏—Ç–º—É –≤—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å –Ω–∞ —Å–≤—ñ–π —Ä–æ–∑—Å—É–¥, –º–∏ –¥–∞–ª—ñ –±—É–¥–µ–º–æ —ó—Ö —Ç—é–Ω–∏—Ç–∏. –†–µ–∫–æ–º–µ–Ω–¥—É—é —Ç—Ä–µ–Ω—É–≤–∞—Ç–∏ –Ω–µ –¥—É–∂–µ —Å–∫–ª–∞–¥–Ω—É –º–æ–¥–µ–ª—å.\n",
        "\n",
        "  –û–ø–∏—Å –≤—Å—ñ—Ö –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ LightGBM - —Ç—É—Ç https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
        "\n",
        "  **–í–∞–∂–ª–∏–≤–æ:** –∑—Ä–æ–±—ñ—Ç—å —Ç–∞–∫—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è LightGBM –∞–±–∏ –≤—ñ–Ω —Å–∞–º–æ—Å—Ç—ñ–π–Ω–æ –æ–±—Ä–æ–±–ª—è–≤ –Ω–µ–∑–∞–ø–æ–≤–Ω–µ–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –≤ –¥–∞–Ω–∏—Ö —ñ –æ–±—Ä–æ–±–ª—è–≤ –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏.\n",
        "\n",
        "  –ê–±–∏ –ø–µ—Ä–µ–¥–∞—Ç–∏ –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏ –≤ LightGBM - –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ –≤–∏—è–≤–∏—Ç–∏ —ó—Ö —ñ–Ω–¥–µ–∫—Å–∏ —ñ –ø–µ—Ä–µ–¥–∞—Ç–∏ –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ `cat_feature=cat_feature_indexes`\n",
        "\n",
        "  –ü—ñ—Å–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ\n",
        "  1. –í–∏–º—ñ—Ä—è–π—Ç–µ —Ç–æ—á–Ω—ñ—Å—Ç—å –∑ –¥–æ–ø–æ–º–æ–≥–æ—é AUROC –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–æ–º—É —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω–æ–º—É –Ω–∞–±–æ—Ä–∞—Ö.\n",
        "  2. –ó—Ä–æ–±—ñ—Ç—å –≤–∏—Å–Ω–æ–≤–æ–∫ –ø—Ä–æ –æ—Ç—Ä–∏–º–∞–Ω—É –º–æ–¥–µ–ª—å: –≤–æ–Ω–∞ —Ö–æ—Ä–æ—à–∞/–ø–æ–≥–∞–Ω–∞, —á–∏ —î high bias/high variance?\n",
        "  3. –ü–æ—Ä—ñ–≤–Ω—è–π—Ç–µ —è–∫—ñ—Å—Ç—å —Ü—ñ—î—ó –º–æ–¥–µ–ª—ñ –∑ —Ç–æ—é, —â–æ –≤–∏ –æ—Ç—Ä–º–∞–ª–∏ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º XGBoostClassifier —Ä–∞–Ω—ñ—à–µ. –ß–∏ –≤–∏–π—à–ª–æ –ø–æ–∫—Ä–∞—â–∏—Ç–∏ —è–∫—ñ—Å—Ç—å?"
      ],
      "metadata": {
        "id": "Vg77SVWrBBmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(raw_df, test_size=0.2, random_state=42, stratify=raw_df[target_col])\n",
        "\n",
        "cat_feature_indexes = [train_df.columns.get_loc(col) for col in categorical_cols]\n",
        "\n",
        "input_cols = [col for col in raw_df.columns if col != target_col]\n",
        "train_inputs, train_targets = train_df[input_cols], train_df[target_col]\n",
        "val_inputs, val_targets = val_df[input_cols], val_df[target_col]\n",
        "\n",
        "lgb_clf = lgb.LGBMClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    boosting_type='gbdt',\n",
        "    random_state=42\n",
        ")\n",
        "lgb_clf.fit(train_inputs, train_targets, categorical_feature=cat_feature_indexes)\n",
        "\n",
        "train_preds_proba = lgb_clf.predict_proba(train_inputs)[:, 1]\n",
        "val_preds_proba = lgb_clf.predict_proba(val_inputs)[:, 1]\n",
        "\n",
        "train_auc = roc_auc_score(train_targets, train_preds_proba)\n",
        "val_auc = roc_auc_score(val_targets, val_preds_proba)\n",
        "\n",
        "print(\"Train AUROC:\", train_auc)\n",
        "print(\"Validation AUROC:\", val_auc)"
      ],
      "metadata": {
        "id": "C-9aZn4d45No",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a7b635-6e2f-4db8-bfca-c331fdc058f1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001089 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 843\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "Train AUROC: 0.975844531400087\n",
            "Validation AUROC: 0.9325752795116263\n",
            "–ë–∞–ª–∞–Ω—Å –º—ñ–∂ bias —ñ variance –≤–∏–≥–ª—è–¥–∞—î –¥–æ–±—Ä–µ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–í–∏—Å–Ω–æ–≤–∫–∏**\n",
        "\n",
        "Train AUROC –≤–¥–∞–ª–æ—Å—å —Ç—Ä–æ—Ö–∏ –ø—ñ–¥—Ç—è–≥–Ω—É—Ç–∏\n"
      ],
      "metadata": {
        "id": "KcyjY9tqNO-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ –±—ñ–±–ª—ñ–æ—Ç–µ–∫—É `Hyperopt` —ñ –ø—Ä–∏–∫–ª–∞–¥ –ø–æ—à—É–∫—É –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –¥–ª—è `LightGBM` –∑ –ª–µ–∫—Ü—ñ—ó –∑–Ω–∞–π–¥—ñ—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ `LightGBM` –¥–ª—è –Ω–∞—à–æ—ó –∑–∞–¥–∞—á—ñ. –ó–∞–¥–∞–π—Ç–µ —Å–≤–æ—é —Å—ñ—Ç–∫—É –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –≤–∏—Ö–æ–¥—è—á–∏ –∑ —Ç–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤, —è–∫—ñ –≤–∏ –± —Ö–æ—Ç—ñ–ª–∏ –ø–µ—Ä–µ–±—Ä–∞—Ç–∏. –ü–æ—Å—Ç–∞–≤—Ç–µ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–∞—É–Ω–¥—ñ–≤ –≤ –ø—ñ–¥–±–æ—Ä—ñ –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ —Ä—ñ–≤–Ω—É **10**.\n",
        "\n",
        "  **–£–≤–∞–≥–∞!** –î–ª—è —Ç–æ–≥–æ, –∞–±–∏ —Å–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏—Å—å hyperopt, –Ω–∞–º —Ç—Ä–µ–±–∞ –∑–∞–¥–∞—Ç–∏ —Ñ—É–Ω–∫—Ü—ñ—é `objective`. –Ü —Ç—É—Ç –º–∏ —Ç–∞–∫–æ–∂ —Å—Ç–∞–≤–∏–º–æ loss - –Ω–µ–≥–∞—Ç–∏–≤–Ω–µ –∑–Ω–∞—á–µ–Ω–Ω—è AUROC, —è–∫ —ñ –ø—Ä–∏ –ø–æ—à—É—Ü—ñ –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –¥–ª—è XGBoost. –î–æ —Ä–µ—á—ñ, –º–æ–∂–Ω–∞ —Å–ø—Ä–æ–±—É–≤–∞—Ç–∏ –Ω–∞–ø–∏—Å–∞—Ç–∏ –∫–æ–¥ —Ç–∞–∫, –∞–±–∏ –≤ objective –ø–µ—Ä–µ–¥–∞–≤–∞—Ç–∏ –ª–∏—à–µ –º–æ–¥–µ–ª—å —ñ –Ω–µ –ø–∏—Å–∞—Ç–∏ —Å—Ö–æ–∂–∏–π –∫–æ–¥ –¥–≤—ñ—á—ñ :)\n",
        "\n",
        "  –ü—ñ—Å–ª—è —É—Å–ø—ñ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –ø–æ—à—É–∫—É –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏—Ö –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤\n",
        "    - –≤–∏–≤–µ–¥—ñ—Ç—å –Ω–∞–π–∫—Ä–∞—â—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤\n",
        "    - —Å—Ç–≤–æ—Ä—ñ—Ç—å –≤ –æ–∫—Ä–µ–º—ñ–π –∑–º—ñ–Ω—ñ–π `final_lgb_clf` –º–æ–¥–µ–ª—å `LightGBM` –∑ –Ω–∞–π–∫—Ä–∞—â–∏–º–∏ –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
        "    - –Ω–∞–≤—á—ñ—Ç—å –º–æ–¥–µ–ª—å `final_lgb_clf`\n",
        "    - –æ—Ü—ñ–Ω—ñ—Ç—å —è–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ `final_lgb_clf` –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ–π —ñ –≤–∞–ª—ñ–¥–∞—Ü—ñ–π–Ω—ñ–π –≤–∏–±—ñ—Ä–∫–∞—Ö –∑ –¥–æ–ø–æ–º–æ–≥–æ—é AUROC.\n",
        "    - –∑—Ä–æ–±—ñ—Ç—å –≤–∏—Å–Ω–æ–≤–æ–∫ –ø—Ä–æ —è–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ. –ß–∏ —Å—Ç–∞–ª–∞ –≤–æ–Ω–∞ –∫—Ä–∞—â–µ –ø–æ—Ä—ñ–≤–Ω—è–Ω–æ –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ–º –ø—É–Ω–∫—Ç–æ–º (4) —Ü—å–æ–≥–æ –∑–∞–≤–¥–∞–Ω–Ω—è?"
      ],
      "metadata": {
        "id": "nCnkGD_sEW1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_lgb(params):\n",
        "    clf = lgb.LGBMClassifier(\n",
        "        **params,\n",
        "        random_state=42\n",
        "    )\n",
        "    clf.fit(train_inputs, train_targets, categorical_feature=cat_feature_indexes)\n",
        "    preds_proba = clf.predict_proba(val_inputs)[:, 1]\n",
        "    return -roc_auc_score(val_targets, preds_proba)\n",
        "\n",
        "space_lgb = {\n",
        "    'n_estimators': hp.choice('n_estimators', [50, 100, 200]),\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "    'num_leaves': hp.choice('num_leaves', [20, 31, 50]),\n",
        "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0)\n",
        "}\n",
        "\n",
        "trials = Trials()\n",
        "best_lgb = fmin(fn=objective_lgb, space=space_lgb, algo=tpe.suggest, max_evals=10, trials=trials)\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_lgb)\n",
        "\n",
        "final_lgb_clf = lgb.LGBMClassifier(\n",
        "    n_estimators=[50, 100, 200][best_lgb['n_estimators']],\n",
        "    learning_rate=best_lgb['learning_rate'],\n",
        "    num_leaves=[20, 31, 50][best_lgb['num_leaves']],\n",
        "    subsample=best_lgb['subsample'],\n",
        "    colsample_bytree=best_lgb['colsample_bytree'],\n",
        "    random_state=42\n",
        ")\n",
        "final_lgb_clf.fit(train_inputs, train_targets, categorical_feature=cat_feature_indexes)\n",
        "\n",
        "train_preds_proba = final_lgb_clf.predict_proba(train_inputs)[:, 1]\n",
        "val_preds_proba = final_lgb_clf.predict_proba(val_inputs)[:, 1]\n",
        "train_auc = roc_auc_score(train_targets, train_preds_proba)\n",
        "val_auc = roc_auc_score(val_targets, val_preds_proba)\n",
        "\n",
        "print(\"Train AUROC:\", train_auc)\n",
        "print(\"Validation AUROC:\", val_auc)"
      ],
      "metadata": {
        "id": "cfMQKA4D47Rq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb48790-7af0-4af9-e350-85ece6edc8e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001237 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 843\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001582 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 843\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001153 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 843\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 843\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001155 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 843\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 843\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003460 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 843\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001792 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 843\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001333 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 843\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002084 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 843\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:02<00:00,  4.12trial/s, best loss: -0.9363001577611633]\n",
            "Best Hyperparameters: {'colsample_bytree': 0.7583442321213254, 'learning_rate': 0.03609858659415139, 'n_estimators': 1, 'num_leaves': 0, 'subsample': 0.5346089782251953}\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000991 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 843\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "Train AUROC: 0.9462170610946505\n",
            "Validation AUROC: 0.9363001577611633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–í–∏—Å–Ω–æ–≤–∫–∏**\n",
        "\n",
        "–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–Ω–æ–≤—É —Ç—Ä–æ—Ö–∏ –≤–ø–∞–ª–∏\n"
      ],
      "metadata": {
        "id": "Z3N2MzWRNo3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. –û–±–µ—Ä—ñ—Ç—å –º–æ–¥–µ–ª—å –∑ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤ –≤ —Ü—å–æ–º—É –î–ó —ñ –∑—Ä–æ–±—ñ—Ç—å –Ω–æ–≤–∏–π `submission` –Ω–∞ Kaggle —Ç–∞ –¥–æ–¥–∞–π—Ç–µ –∫–æ–¥ –¥–ª—è —Ü—å–æ–≥–æ —ñ —Å–∫—Ä—ñ–Ω—à–æ—Ç —Å–∫–æ—Ä–∞ –Ω–∞ –ø—É–±–ª—ñ—á–Ω–æ–º—É –ª—ñ–¥–µ—Ä–±–æ—Ä–¥—ñ.\n",
        "  \n",
        "  **–ù–∞–ø–∏—à—ñ—Ç—å –∫–æ–º–µ–Ω—Ç–∞—Ä, —á–æ–º—É –≤–∏ –æ–±—Ä–∞–ª–∏ —Å–∞–º–µ —Ü—é –º–æ–¥–µ–ª—å?**\n",
        "\n",
        "  –Ü —è –≤–∞—Å –≤—ñ—Ç–∞—é - —Ü–µ –æ—Å—Ç–∞–Ω–Ω—î –∑–∞–≤–¥–∞–Ω–Ω—è –∑ —Ü–∏–º –Ω–∞–±–æ—Ä–æ–º –¥–∞–Ω–∏—Ö üí™ –ù–∞ —Ü—å–æ–º—É –µ—Ç–∞–ø—ñ –∫–æ—Ä–∏—Å–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏, —è–∫—ñ –º–æ–¥–µ–ª—ñ –ø–æ–∫–∞–∑–∞–ª–∏ —Å–µ–±–µ –Ω–∞–π–∫—Ä–∞—â–µ —ñ –ø–æ–¥—É–º–∞—Ç–∏, —á–æ–º—É."
      ],
      "metadata": {
        "id": "XArADR2CG8VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "submission_ids = test_df[\"id\"]\n",
        "\n",
        "test_df = test_df.drop(columns=[\"id\", \"CustomerId\", \"Surname\"])\n",
        "\n",
        "test_df[\"Geography\"] = test_df[\"Geography\"].astype(\"category\")\n",
        "test_df[\"Gender\"] = test_df[\"Gender\"].astype(\"category\")\n",
        "\n",
        "submission_preds = final_lgb_clf.predict_proba(test_df)[:, 1]\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"id\": submission_ids,\n",
        "    \"Exited\": submission_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "COIjJH9f5SSp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![–ó–Ω—ñ–º–æ–∫ –µ–∫—Ä–∞–Ω–∞ 2025-03-07 –æ 12.51.28.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "9PVSrvPEMw11"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9KR9hPXJMzrB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}